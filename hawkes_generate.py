# --- In hawkes_generate.py ---
"""
ðŸŽ¯ PROGRESSIVE K MATRIX HAWKES SIMULATION

This script generates Hawkes process simulations with manually controlled K matrices.
Start with simple patterns and gradually increase complexity for better understanding.

K MATRIX PATTERNS:
1. 'simple'   - Uniform positive excitation (good starting point)
2. 'diagonal' - Self-excitation + neighbor effects (test self-reinforcement)
3. 'local'    - Distance-based influence (geographic realism)
4. 'custom'   - Hub-based structure (network effects)
5. 'random'   - Random values (comparison baseline)

PROGRESSION STRATEGY:
1. Start with 'simple' pattern to verify basic model functionality
2. Move to 'diagonal' to test self-excitation vs neighbor excitation
3. Try 'local' for spatial realism in traffic flow
4. Use 'custom' for complex network dynamics
5. Compare with 'random' to validate improvements

Change k_pattern variable in the code to experiment!
"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from scipy.optimize import minimize
import hawkes_module as hawkes
from mpi4py import MPI
import osmnx as ox
import networkx as nx
import geopandas as gpd
from sklearn.cluster import KMeans
from time import perf_counter
import pickle

# Initialize MPI
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()

# Configuration parameters  
num_nodes = 20                     # Realistic number of traffic detectors for a city area
num_event_types = 2               # High, Low Flow (keeping it simple)
simulation_time = 24*31*12            # 24 hours = 1 full day (using HOURS as time unit)
num_hops = 1                      # Keep 1 hop for computational efficiency  
pickle_filename = "traffic_hawkes_simulation2.pickle"

# OPTIMIZATION PARAMETERS
temporal_window_factor = 3.0      # Events older than 3*avg_delta_t won't affect intensity
spatial_cutoff_factor = 2.0       # Events beyond 2*sigma_spatial distance ignored

# Define helper function that only runs on rank 0
def rank0_print(message):
    if rank == 0:
        print(message)

# True parameters (only rank 0 initializes true parameters and simulation)
if rank == 0:
    start_time = perf_counter()
    np.random.seed(42 + rank)  # Different seed for each rank
    
    rank0_print("=" * 80)
    rank0_print("ðŸš€ OPTIMIZED HAWKES PROCESS SIMULATION")
    rank0_print(f"âœ… Temporal window: {temporal_window_factor}x avg_delta_t")
    rank0_print(f"âœ… Spatial cutoff: {spatial_cutoff_factor}x sigma_spatial")
    rank0_print(f"âœ… Network reachability: {num_hops} hops")
    rank0_print("=" * 80)
    
    # Create parameters with proper shape from the beginning
    # Target: ~200 events per day with 15 nodes Ã— 2 types = 30 combinations
    # Using HOURS as time unit: mu â‰ˆ 200/(30 Ã— 24) â‰ˆ 0.28 events/hour per (node,type)
    # Reduce slightly for excitation effects
    mu_true = np.ones((num_nodes, num_event_types)) * 0.005  # Realistic baseline: 0.25 events/hour
    
    # === MANUAL K MATRIX CONFIGURATION ===
    # Start with controlled, interpretable patterns
    
    # Choose K matrix pattern: 'simple', 'diagonal', 'local', 'random'
    k_pattern = 'simple'  # Change this to experiment with different patterns
    
    if k_pattern == 'simple':
        # Simple pattern: small uniform positive excitation for connected nodes
        K_true_interaction = np.full((num_nodes, num_nodes), 0.1)  # Uniform positive excitation
        # Set diagonal to zero (no self-excitation)
        np.fill_diagonal(K_true_interaction, 0.0)
        
    elif k_pattern == 'diagonal':
        # Diagonal-dominant pattern: self-excitation + small neighbor effects
        K_true_interaction = np.zeros((num_nodes, num_nodes))
        np.fill_diagonal(K_true_interaction, 0.2)  # Self-excitation
        # Add small neighbor effects (will be masked by adjacency later)
        K_true_interaction += 0.05  # Small uniform neighbor excitation
        np.fill_diagonal(K_true_interaction, 0.2)  # Restore diagonal
        
    elif k_pattern == 'local':
        # Local influence pattern: stronger effects for nearby nodes
        K_true_interaction = np.zeros((num_nodes, num_nodes))
        for i in range(num_nodes):
            for j in range(num_nodes):
                if i != j:
                    # Simulated distance-based effect (will be refined by actual adjacency)
                    K_true_interaction[i, j] = 0.15 * np.exp(-0.1 * abs(i - j))
                    
    elif k_pattern == 'custom':
        # Custom pattern: manually specify interesting structure
        K_true_interaction = np.zeros((num_nodes, num_nodes))
        # Create hub nodes (nodes 0, 5, 10, 15) with stronger influence
        hub_nodes = [0, 5, 10, 15]
        for hub in hub_nodes:
            K_true_interaction[hub, :] = 0.2  # Hubs influence others strongly
            K_true_interaction[:, hub] = 0.1  # Hubs are influenced moderately
        # Set diagonal to zero
        np.fill_diagonal(K_true_interaction, 0.0)
        
    else:  # 'random' or fallback
        # Original random pattern (for comparison)
        K_true_interaction = np.random.uniform(-0.1, 0.2, size=(num_nodes, num_nodes))
    
    # Initialize K matrix
    K_true = K_true_interaction.copy()
    
    rank0_print(f"K matrix pattern: '{k_pattern}'")
    rank0_print(f"K matrix statistics before network constraints:")
    rank0_print(f"  Min: {np.min(K_true_interaction):.3f}")
    rank0_print(f"  Max: {np.max(K_true_interaction):.3f}")
    rank0_print(f"  Mean: {np.mean(K_true_interaction):.3f}")
    rank0_print(f"  Non-zero entries: {np.count_nonzero(K_true_interaction)}/{num_nodes**2}")

    sigma_spatial_true = 2.0    # Spatial influence range (unchanged, distance-based)
    omega_temporal_true = 1.0   # Temporal decay: ~1 hour influence time (appropriate for traffic)
    
    rank0_print(f"True parameters:")
    rank0_print(f"  Ïƒ_spatial = {sigma_spatial_true}")
    rank0_print(f"  Ï‰_temporal = {omega_temporal_true}")
    rank0_print(f"  Î¼ baseline = {mu_true[0,0]:.6f} events/hour")
    rank0_print(f"  K range = [{np.min(K_true_interaction):.3f}, {np.max(K_true_interaction):.3f}]")
    
    rank0_print(f"Downloading road network for Zurich, Switzerland...")
    # 1. Download the drivable road network for a city
    place_name = "Zurich, Switzerland"
    G = ox.graph_from_place(place_name, network_type="drive")

    # 2. Convert the graph to GeoDataFrames (nodes + edges)
    nodes_gdf, edges_gdf = ox.graph_to_gdfs(G)
    node_ids = list(nodes_gdf.index)

    # 3. Cluster the node coordinates
    rank0_print(f"Clustering node coordinates into {num_nodes} clusters...")
    coords = nodes_gdf[['x', 'y']].values
    kmeans = KMeans(n_clusters=num_nodes, random_state=42, n_init=10)
    labels = kmeans.fit_predict(coords)
    centroids = kmeans.cluster_centers_

    # 4. Normalize coordinates
    x_min, x_max = centroids[:, 0].min(), centroids[:, 0].max()
    y_min, y_max = centroids[:, 1].min(), centroids[:, 1].max()

    # Avoid division by zero
    x_range = x_max - x_min if x_max != x_min else 1
    y_range = y_max - y_min if y_max != y_min else 1

    # Use numpy operations for efficiency
    norm_x = 10.0 * (centroids[:, 0] - x_min) / x_range
    norm_y = 10.0 * (centroids[:, 1] - y_min) / y_range
    norm_centroids = np.column_stack((norm_x, norm_y))

    # 5. Create a "super-graph" with nodes
    super_G = nx.Graph()
    for c in range(num_nodes):
        nx_c, ny_c = norm_centroids[c]
        super_G.add_node(c, x=nx_c, y=ny_c)

    # 6. Add edges and build adjacency matrix directly
    id_to_idx = {nid: i for i, nid in enumerate(node_ids)}
    adjacency_matrix = np.zeros((num_nodes, num_nodes))
    
    # Process all edges at once using numpy operations if possible
    for u, v in G.edges():
        u_cluster = labels[id_to_idx[u]]
        v_cluster = labels[id_to_idx[v]]
        if u_cluster != v_cluster:
            super_G.add_edge(u_cluster, v_cluster)
            adjacency_matrix[u_cluster, v_cluster] = adjacency_matrix[v_cluster, u_cluster] = 1

    node_locations = norm_centroids
    
    # Calculate network metrics
    rank0_print("Calculating reachability matrices and connectivity...")
    neighbors_list = [np.where(adjacency_matrix[u, :])[0] for u in range(num_nodes)]
    reachability_matrix = hawkes.calculate_reachability_matrix(adjacency_matrix, num_hops)
    extended_neighbors_list = hawkes.create_extended_neighbors_list(reachability_matrix)
    
    # Network analysis
    network_density = np.sum(adjacency_matrix) / (num_nodes * (num_nodes - 1))
    avg_neighbors = np.mean([len(neighbors) for neighbors in neighbors_list])
    
    rank0_print(f"Network analysis:")
    rank0_print(f"  Density: {network_density:.3f} ({network_density*100:.1f}%)")
    rank0_print(f"  Avg neighbors per node: {avg_neighbors:.1f}")
    rank0_print(f"  Total connections: {int(np.sum(adjacency_matrix))}")
    
    # Apply reachability constraints to K matrix
    K_true_before_constraints = K_true.copy()
    K_true = K_true * reachability_matrix
    
    rank0_print(f"K matrix statistics after network constraints:")
    rank0_print(f"  Min: {np.min(K_true):.3f}")
    rank0_print(f"  Max: {np.max(K_true):.3f}")
    rank0_print(f"  Mean: {np.mean(K_true):.3f}")
    rank0_print(f"  Non-zero entries: {np.count_nonzero(K_true)}/{num_nodes**2}")
    
    # Show how many connections were preserved vs eliminated
    original_nonzero = np.count_nonzero(K_true_before_constraints)
    final_nonzero = np.count_nonzero(K_true)
    rank0_print(f"  Network constraint effect: {final_nonzero}/{original_nonzero} connections preserved ({final_nonzero/original_nonzero*100:.1f}%)")
    
    # Visualize K matrix pattern
    if num_nodes <= 10:  # Only for small matrices to avoid clutter
        rank0_print(f"Final K matrix (first 10x10):")
        rank0_print(K_true[:10, :10])
    else:
        rank0_print(f"Final K matrix sample (top-left 5x5):")
        rank0_print(K_true[:5, :5])
        
    # Create a simple K matrix plot if matplotlib is available
    try:
        import matplotlib.pyplot as plt
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # Plot adjacency matrix
        im1 = ax1.imshow(adjacency_matrix, cmap='Blues', vmin=0, vmax=1)
        ax1.set_title('Network Adjacency Matrix')
        ax1.set_xlabel('Node Index')
        ax1.set_ylabel('Node Index')
        plt.colorbar(im1, ax=ax1, shrink=0.8)
        
        # Plot K matrix
        im2 = ax2.imshow(K_true, cmap='RdBu_r', vmin=np.min(K_true), vmax=np.max(K_true))
        ax2.set_title(f'K Matrix Pattern: {k_pattern}')
        ax2.set_xlabel('Node Index')
        ax2.set_ylabel('Node Index')
        plt.colorbar(im2, ax=ax2, shrink=0.8)
        
        plt.tight_layout()
        plt.savefig(f'k_matrix_pattern_{k_pattern}.png', dpi=150, bbox_inches='tight')
        plt.close()
        rank0_print(f"  K matrix visualization saved: k_matrix_pattern_{k_pattern}.png")
        
    except ImportError:
        rank0_print("  (matplotlib not available for K matrix visualization)")

    # Mark Kernel Parameters - Matrix for traffic flow influence
    # How different flow types influence each other
    mark_kernel_matrix = np.array([
        [0.8, 0.9],   # From Low Flow (0) to [Low, High] - low flow can trigger more low/high
        [0.9, 0.9]    # From High Flow (1) to [Low, High] - high flow strongly triggers more high flow
    ])
    mark_kernel_type = 'matrix'

    rank0_print(f"Mark kernel matrix:")
    rank0_print(f"  {mark_kernel_matrix}")

    # Pack parameters for simulation
    params_init = np.concatenate([
        mu_true.flatten(),
        K_true.flatten(),
        [omega_temporal_true, sigma_spatial_true]
    ])
    
    # Expected event calculation with optimizations
    rank0_print(f"Expected performance with optimizations:")
    baseline_events = num_nodes * num_event_types * mu_true[0,0] * simulation_time
    rank0_print(f"  Baseline events (no excitation): ~{baseline_events:.0f}")
    rank0_print(f"  Expected total events: ~{baseline_events * 1.2:.0f} (with excitation)")
    rank0_print(f"  Spatial cutoff distance: {spatial_cutoff_factor * sigma_spatial_true:.1f}")
    rank0_print(f"  Temporal window (initial): {temporal_window_factor:.1f} Ã— avg_delta_t")
    
    # Simulate the process with OPTIMIZATIONS
    rank0_print(f"\nðŸš€ Starting OPTIMIZED Hawkes process simulation...")
    rank0_print(f"   Duration: {simulation_time} hours")
    rank0_print(f"   Optimizations: Temporal + Spatial + Network windows")
    
    # Use original simulation function (it already has network optimization)
    events = hawkes.simulate_hawkes_process(
        num_nodes, num_event_types, simulation_time,
        mu_true, K_true, sigma_spatial_true, omega_temporal_true, node_locations,
        extended_neighbors_list,
        nonlinearity='linear', mark_kernel_type=mark_kernel_type, 
        mark_kernel_matrix=mark_kernel_matrix
    )
    
    # Convert to structured array for faster processing
    dt_dtype = np.dtype([('t', float), ('u', int), ('e', int), ('x', float), ('y', float)])
    events = np.array(events, dtype=dt_dtype)
    
    simulation_duration = perf_counter() - start_time
    rank0_print(f"\nâœ… OPTIMIZED simulation completed!")
    rank0_print(f"   Events generated: {len(events)}")
    rank0_print(f"   Simulation time: {simulation_duration:.2f} seconds")
    rank0_print(f"   Events per second: {len(events)/simulation_duration:.1f}")
    
    # Calculate daily event statistics
    if len(events) > 0:
        rank0_print(f"\n=== OPTIMIZED TRAFFIC EVENT STATISTICS ===")
        rank0_print(f"Total events in simulation: {len(events)}")
        events_per_hour = len(events) / simulation_time
        rank0_print(f"Average events per hour: {events_per_hour:.1f}")
        rank0_print(f"Average events per node per hour: {events_per_hour/num_nodes:.3f}")
        
        # Calculate actual average delta_t for verification
        times = events['t']
        actual_delta_t = np.mean(np.diff(np.sort(times)))
        actual_temporal_window = temporal_window_factor * actual_delta_t
        actual_spatial_cutoff = spatial_cutoff_factor * sigma_spatial_true
        
        rank0_print(f"\nOptimization window sizes:")
        rank0_print(f"  Actual avg Î”t: {actual_delta_t:.3f} hours")
        rank0_print(f"  Temporal window: {actual_temporal_window:.3f} hours")
        rank0_print(f"  Spatial cutoff: {actual_spatial_cutoff:.3f} units")
        
        # Event type breakdown
        event_types = events['e']
        type_counts = np.bincount(event_types, minlength=num_event_types)
        for i, count in enumerate(type_counts):
            flow_type = "Low Flow" if i == 0 else "High Flow"
            percentage = count/len(events)*100
            rank0_print(f"  {flow_type} events: {count} ({percentage:.1f}%)")
        
        # Network utilization analysis
        event_nodes = events['u']
        node_counts = np.bincount(event_nodes, minlength=num_nodes)
        active_nodes = np.sum(node_counts > 0)
        rank0_print(f"\nNetwork utilization:")
        rank0_print(f"  Active nodes: {active_nodes}/{num_nodes} ({active_nodes/num_nodes*100:.1f}%)")
        rank0_print(f"  Most active node: {np.max(node_counts)} events")
        rank0_print(f"  Least active node: {np.min(node_counts)} events")

    # Visualization (only if events are generated)
    if events.size > 0:
        rank0_print("Generating visualizations...")
        hawkes.plot_events_3d(events, title=f"3D Optimized Traffic Flow Hawkes Simulation")
        hawkes.plot_events_time_series(events, num_nodes, num_event_types)
        hawkes.analyze_event_times(events)
        hawkes.plot_spatial_event_locations_2d(events, title="2D Traffic Detector Locations with Optimized Flow Events")
        hawkes.plot_event_type_distribution(events, num_event_types, title="Optimized Traffic Flow Event Type Distribution")
    
    # Save data with optimization parameters
    rank0_print(f"Saving optimized simulation data to {pickle_filename}...")
    
    # Add optimization parameters and K matrix info to save
    optimization_params = {
        'temporal_window_factor': temporal_window_factor,
        'spatial_cutoff_factor': spatial_cutoff_factor,
        'actual_delta_t': actual_delta_t if len(events) > 0 else None,
        'actual_temporal_window': actual_temporal_window if len(events) > 0 else None,
        'actual_spatial_cutoff': actual_spatial_cutoff if len(events) > 0 else None,
        'k_pattern': k_pattern,
        'k_matrix_stats': {
            'min': float(np.min(K_true)),
            'max': float(np.max(K_true)),
            'mean': float(np.mean(K_true)),
            'nonzero_count': int(np.count_nonzero(K_true)),
            'total_entries': int(num_nodes**2),
            'sparsity': float(1 - np.count_nonzero(K_true)/(num_nodes**2))
        }
    }
    
    hawkes.save_simulation_data(
        pickle_filename, events, params_init, num_nodes, num_event_types,
        node_locations, adjacency_matrix, neighbors_list,
        'linear', mark_kernel_type=mark_kernel_type, mark_kernel_matrix=mark_kernel_matrix, num_hops=num_hops
    )
    
    # Save optimization parameters separately
    with open(pickle_filename, 'rb') as f:
        data = pickle.load(f)
    data['optimization_params'] = optimization_params
    with open(pickle_filename, 'wb') as f:
        pickle.dump(data, f)
    
    rank0_print(f"\nâœ… All data saved with optimization parameters!")
    
else:
    # For other ranks, initialize empty variables to receive broadcasted data
    events = None
    params_init = None
    node_locations = None
    extended_neighbors_list = None
    mark_kernel_type = None
    mark_kernel_matrix = None

# MPI broadcast - Send simulation data to all processes
rank0_print("Broadcasting optimized simulation data to all MPI processes...")

# Broadcast necessary variables from rank 0 to all other ranks
# Use proper order and ensure all ranks have the same variables
num_nodes = comm.bcast(num_nodes, root=0)
num_event_types = comm.bcast(num_event_types, root=0)
node_locations = comm.bcast(node_locations, root=0)
extended_neighbors_list = comm.bcast(extended_neighbors_list, root=0)
mark_kernel_type = comm.bcast(mark_kernel_type, root=0)
mark_kernel_matrix = comm.bcast(mark_kernel_matrix, root=0)
params_init = comm.bcast(params_init, root=0)
events = comm.bcast(events, root=0)

# Evaluate NLL multiple times to verify consistency with optimized data
rank0_print("Evaluating NLL with true parameters on optimized data...")

# Run calculations 3 times (reduced from 5 for speed)
nll_values = []
for run in range(3):
    nll = hawkes.calculate_nll(
        params_init, events, num_nodes, num_event_types, node_locations, 
        extended_neighbors_list, nonlinearity='linear', 
        mark_kernel_type=mark_kernel_type, mark_kernel_matrix=mark_kernel_matrix
    )
    if rank == 0:
        nll_values.append(nll)
        rank0_print(f"NLL evaluation run {run+1}: {nll:.6f}")

if rank == 0:
    average_nll = sum(nll_values) / len(nll_values)
    nll_std = np.std(nll_values)
    rank0_print(f"\nðŸ“Š NLL CONSISTENCY CHECK:")
    rank0_print(f"   Average NLL: {average_nll:.6f}")
    rank0_print(f"   Std deviation: {nll_std:.8f}")
    rank0_print(f"   Coefficient of variation: {nll_std/abs(average_nll)*100:.6f}%")
    
    if nll_std/abs(average_nll) < 1e-6:
        rank0_print("   âœ… Excellent consistency!")
    elif nll_std/abs(average_nll) < 1e-4:
        rank0_print("   âœ… Good consistency")
    else:
        rank0_print("   âš ï¸  Check numerical stability")
    
    rank0_print(f"\n" + "=" * 80)
    rank0_print("ðŸŽ‰ OPTIMIZED TRAFFIC FLOW SIMULATION COMPLETED!")
    rank0_print(f"âœ… Temporal + Spatial + Network optimization applied")
    rank0_print(f"âœ… {len(events)} events generated in {simulation_duration:.1f} seconds")
    rank0_print(f"âœ… Data saved with optimization parameters")
    rank0_print(f"âœ… Ready for optimized Bayesian inference")
    rank0_print("=" * 80)